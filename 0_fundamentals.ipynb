{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualizaciÃ³n en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%autosave 0\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#import pyro\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from functools import partial\n",
    "slider_layout = widgets.Layout(width='600px', height='20px')\n",
    "slider_style = {'description_width': 'initial'}\n",
    "IntSlider_nice = partial(widgets.IntSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "FloatSlider_nice = partial(widgets.FloatSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "SelSlider_nice = partial(widgets.SelectionSlider, style=slider_style, layout=slider_layout, continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random/Stochastic Variable (RV)\n",
    "\n",
    "A variable to map the output of a random process: *throwing a coin/dice, predicting weather*\n",
    "- Denoted by a capital letter: $X$\n",
    "\n",
    "We don't know its value until we draw/sample from it: We observe the RV\n",
    "- Observations are denoted with lowercase letters: $x \\sim X$\n",
    "\n",
    "We describe a RV through its domain and probability density/mass function\n",
    "\n",
    "##### Example: Fair six-faced dice\n",
    "\n",
    "- Domain (possible outputs): $[1, 2, 3, 4, 5, 6]$\n",
    "- Probability mass function (discrete uniform): $[\\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}]$\n",
    "\n",
    "##### Calisthenics:\n",
    "- The probability of drawing a $1$ is $P(X=1) = P(1) = \\frac{1}{6}$\n",
    "- The probability of drawing a number greater or equal than $5$ is $P(X\\geq 5) = \\frac{1}{3}$\n",
    "- The probability of drawing and odd number is $P(\\text{odd}) = \\frac{1}{2}$\n",
    "\n",
    "### Joint, Marginal and Conditional probabilities\n",
    "\n",
    "If we have two or more random variables we can define their joint pdf/pmf: $P(X,Y)$\n",
    "\n",
    "From the joint we sum to obtain the marginal of $X$ or $Y$. This is the:\n",
    "\n",
    "**Law of total probability (sum rule)**:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(Y=y) &= \\sum_{x \\in \\mathcal{X}} P(X=x, Y=y) \\nonumber \\\\\n",
    "&= \\sum_{x \\in \\mathcal{X}} P(Y=y|X=x) P(X=x),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $P(Y=y|X=x)$ is the conditional probability of $y$ given $x$\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)}\n",
    "$$\n",
    "\n",
    "(iif $P(X=x) \\neq 0$)\n",
    "\n",
    "this is a special case of the \n",
    "\n",
    "**Chain rule of probabilities (product rule)**:\n",
    "\n",
    "For example with four variables:\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_1, x_2, x_3, x_4) &= P(x_4|x_3, x_2, x_1) P(x_3, x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2 |x_1) P(x_1) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Bayes Theorem\n",
    "\n",
    "Combining the product and sum rule for two random variables we can write\n",
    "\n",
    "\n",
    "$$\n",
    "P(y | x) = \\frac{P(x|y) P(y)}{P(x)} = \\frac{P(x|y) P(y)}{\\sum_{y\\in\\mathcal{Y}} P(x|y) P(y)}\n",
    "$$\n",
    "\n",
    "We call $P(y|x)$ the **posterior** distribution of $y$: \n",
    "> What we know of $y$ after we observe $x$ \n",
    "\n",
    "We call $P(y)$ the **prior** distribution of $y$\n",
    "> What we know of $y$ before observing $x$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8.5, 3.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.view_init(elev=45., azim=-45)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "x = np.arange(-4, 5, 1); y = np.arange(-4, 5, 1)\n",
    "X, Y = np.meshgrid(x, y); XY = np.zeros_like(X)\n",
    "XY[-3, 2:-2] = 1; XY[2, 2:-2] = 1; XY[2:-2, 4] = 1\n",
    "XY = XY/np.sum(XY)\n",
    "\n",
    "def update_plot(x_cond):\n",
    "    ax.cla()\n",
    "    ax.bar(x, np.sum(XY, axis=1), zdir='x', color='b', zs=-4)\n",
    "    ax.bar(y, np.sum(XY, axis=0), zdir='y', color='r', zs=5)\n",
    "    colors = np.array([['m']*len(x)]*len(y))\n",
    "    colors[:, x_cond-5] = 'b'\n",
    "    ax.bar3d(X.ravel(), Y.ravel(), np.zeros_like(XY.ravel()), 1, 1, XY.ravel(), color=colors.ravel())\n",
    "    ax.set_xlim([-4, 5]); ax.set_xlabel('X')\n",
    "    ax.set_ylim([-4, 5]); ax.set_ylabel('Y')\n",
    "    ax2.cla()\n",
    "    ax2.bar(y, XY[X==x_cond]/np.sum(XY[X==x_cond]), color='b')\n",
    "    ax2.set_title(\"P(Y|X={0})\".format(x_cond))\n",
    "    ax2.set_ylim([0, 0.55])\n",
    "    ax2.set_xlim([-4, 4])\n",
    "    \n",
    "widgets.interact(update_plot, x_cond=IntSlider_nice(min=-4, max=4, value=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independence**\n",
    "\n",
    "Two independent RV:\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x, y)  &= P(x)P(y|x)\\nonumber \\\\\n",
    "&= P(x)P(y) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> Knowing that $x$ happened does not help me to know if $y$ happened\n",
    "\n",
    "**Conditional independence**\n",
    "\n",
    "Two RVs are conditionally independent given a third one\n",
    "$$\n",
    "P(x, y|z)  = P(x|z)P(y|z)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The meaning of probability\n",
    "\n",
    "**Meaning 1:** We observe the outcome of a random experiment (event) several times and we count\n",
    "\n",
    "We flip a coin 5 times and get [x, x, o, x, o]\n",
    "\n",
    "- The probability of x is 3/5\n",
    "- The probability of o is 2/5\n",
    "\n",
    "We have estimated the probability from the **frequency** of x and o\n",
    "\n",
    "> This is called the **Frequentist** interpretation of probability\n",
    "\n",
    "**Meaning 2:** Probability is the **degree of belief** of an event\n",
    "\n",
    "Probabilities describe **assumptions** and also describe **inference given those assumptions**\n",
    "\n",
    "> This is called the **Bayesian** interpretation of probability\n",
    "\n",
    "#### What is the difference for us?\n",
    "\n",
    "Main difference is on the inference\n",
    "- Frequentist: Write the likelihood, get its maximum: **point estimates**\n",
    "- Bayesian: Parameters have distributions too: **Set priors get posteriors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drawing conclusions from facts/evidence through reasoning and scientific premises\n",
    "\n",
    "In our case\n",
    "\n",
    "> Find the least uncertain answer to a problem based on data and a model \n",
    "\n",
    "- Our scientific premises and assumptions goes into the model\n",
    "- The facts are the data\n",
    "\n",
    "### Tasks in statistical inference\n",
    "\n",
    "- Level 1: Fit a model to the data\n",
    "- Level 2: Compare and validate between models\n",
    "- Level 3: Answer questions with our model: **Hypothesis testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1: Maximum likelihood\n",
    "\n",
    "We have a model $\\mathcal{M}_i$ with parameters $\\theta$\n",
    "\n",
    "> We want to estimate $\\theta~$ that best fit the data $\\mathcal{D}$\n",
    "\n",
    "We start by writing Bayes Theorem\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_i) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_i) p(\\theta|\\mathcal{M}_i)}{p(\\mathcal{D}|\\mathcal{M}_i)}\n",
    "$$\n",
    "\n",
    "In the **bayesian approach** we want to find the posterior of $\\theta~$\n",
    "\n",
    "But let's start with the following\n",
    "\n",
    "- we only care for a point estimate of $\\theta~$ \n",
    "- we assume that the prior distribution $p(\\theta|\\mathcal{M}_i)$ is uniform (uninformative) \n",
    "\n",
    "Then we can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta p(\\mathcal{D}| \\theta, \\mathcal{M}_i) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is known as the **Maximum likelihood estimator (MLE)** of $\\theta~$\n",
    "\n",
    "The forms the basis of **frequentist approach** for parameter estimation\n",
    "- Propose a likelihood\n",
    "- Get its arg maximum\n",
    "\n",
    "and we can see it as particular case of the bayesian approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Bernoulli distribution\n",
    "\n",
    "A distribution for binary outcomes $x\\in \\{0, 1\\}$\n",
    "\n",
    "The pmf is\n",
    "$$\n",
    "p(x|p) = \\begin{cases} p & \\text{if } x=1 \\\\ 1-p & \\text{if } x=0  \\end{cases}\n",
    "$$\n",
    "\n",
    "which can be written as \n",
    "$$\n",
    "p(x|p) = p^x (1-p)^{1-x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "@widgets.interact(p=FloatSlider_nice(min=0, max=1, value=0.5, step=0.1))\n",
    "def update(p):\n",
    "    x = scipy.stats.bernoulli.rvs(p, size=1000)\n",
    "    ax.cla()\n",
    "    ax.hist(x, density=True, range=(0, 1), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE for a coin\n",
    "\n",
    "Observations from a coin \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = [x_1, x_2, \\ldots, x_N]\n",
    "$$\n",
    "\n",
    "where $x_i \\in \\{0, 1\\}$\n",
    "\n",
    "**Assumption 1:** Observations are **independent and identically distributed (iid)**\n",
    "\n",
    "$$\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_i) = \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_i)\n",
    "$$\n",
    "\n",
    "**Assumption 2:** Bernoulli model with parameter $\\theta \\in [0, 1]$ for the observations\n",
    "\n",
    "$$\n",
    "p(x_i|\\theta, \\mathcal{M}_i) = \\theta^{x_i} (1- \\theta)^{1-x_i}\n",
    "$$\n",
    "\n",
    "\n",
    "> What is the MLE of $\\theta~$?\n",
    "\n",
    "**Trick of the trade:** The arg maximum of $p(x)$ is the same as $\\log p(x)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\mathcal{D}| \\theta, \\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can take the derivate, set it to zero, and get the MLE \n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors and Maximum a Posteriori\n",
    "\n",
    "Let's lift the assumption that the prior is uniform \n",
    "\n",
    "- We are still looking for a point estimate of $\\theta~$ \n",
    "- We keep the *iid* assumption and we consider the \"log trick\"\n",
    "\n",
    "We can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_i) p(\\theta|\\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_i) + \\log p(\\theta|\\mathcal{M}_i) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is called the **Maximum a posteriori (MAP)** estimate of $\\theta~ $\n",
    "\n",
    "The MAP estimate corresponds to the mode of $p(\\theta|\\mathcal{D}, \\mathcal{M}_i)$\n",
    "\n",
    "#### In addition to the model (likelihood) we have to set the prior $p(\\theta)$\n",
    "\n",
    "This can be a [sensible choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Beta distribution\n",
    "\n",
    "A distribution for $x \\in [0, 1]$, *e.g* probabilities\n",
    "\n",
    "The pdf is \n",
    "\n",
    "$$\n",
    "\\text{Beta}(x|\\alpha, \\beta) = \\frac{x^{\\alpha-1} (1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "where $B(x,y) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ and $\\Gamma(x)$ is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function)\n",
    "\n",
    "For $\\alpha=\\beta=1$ we get the Uniform distribution in $[0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "@widgets.interact(alpha=FloatSlider_nice(min=0.001, max=10, value=0.5, step=0.1), \n",
    "                  beta=FloatSlider_nice(min=0.001, max=10, value=0.5, step=0.1))\n",
    "def update(alpha, beta):\n",
    "    x = scipy.stats.beta.rvs(alpha, beta, size=1000)\n",
    "    ax.cla()\n",
    "    ax.hist(x, density=True, range=(0, 1), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map for the coin\n",
    "\n",
    "\n",
    "We will use a Beta prior for $\\theta ~$\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_i) = \\text{Beta}(\\theta| \\alpha, \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "Omitting the terms that do not depend on $\\theta~$ we get the MAP \n",
    "$$\n",
    "\\hat \\theta= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) +(\\alpha -1) \\log(\\theta) + ( \\beta -1) \\log(1-\\theta) \n",
    "$$\n",
    "\n",
    "By setting the derivate to zero we obtain\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N+\\alpha - \\beta} (\\alpha -1 + \\sum_{i=1}^N x_i)\n",
    "$$\n",
    "\n",
    "Note that it reduces to the MLE for $\\alpha=\\beta=1$ (uniform)\n",
    "\n",
    "\n",
    "> If we know something about the coin before observing the data we add it through $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference\n",
    "\n",
    "With MAP and MLE we get point estimates\n",
    "\n",
    "> How good are these estimates? Can we trust them? What is their uncertainty?\n",
    "\n",
    "We answer this through confidence interval, bootstrap, cross-validation\n",
    "\n",
    "In a \"full\" Bayesian approach we select likelihood/prior and aim for the posterior of $\\theta~$,\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_i) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_i) p(\\theta|\\mathcal{M}_i)}{p(\\mathcal{D}|\\mathcal{M}_i)}\n",
    "$$\n",
    "\n",
    "> If we have the posterior we know everything about $\\theta~$\n",
    "\n",
    "But, how do we get the posterior?\n",
    "\n",
    "### Analytical posterior\n",
    "\n",
    "In some \"very special cases\" the posterior is analytically tractable\n",
    "\n",
    "Enter the [**conjugate priors**](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior for the coin\n",
    "\n",
    "\n",
    "The likelihood of the coin (Bernoulli) is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_i) &= \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_i) \\nonumber \\\\\n",
    "&= \\prod_{i=1}^N \\theta^{x_i} (1-\\theta)^{1-x_i} \\nonumber \\\\\n",
    "&= \\theta^{\\sum_i x_i}(1-\\theta)^{N-\\sum_i x_i} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The prior is Beta\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_i) = \\text{Beta}(\\theta| \\alpha , \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "The posterior is\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_i) = \\frac{1}{Z} \\theta^{\\alpha +\\sum_i x_i - 1}(1-\\theta)^{\\beta +N-\\sum_i x_i-1},\n",
    "$$\n",
    "where $Z$ is a normalizing constant\n",
    "\n",
    "We recognize that the posterior is also Beta:\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_i) = \\text{Beta}(\\theta| \\hat \\alpha , \\hat \\beta),\n",
    "$$\n",
    "\n",
    "with $\\hat \\alpha= \\alpha +\\sum_i x_i$ and $\\hat \\beta= \\beta +N-\\sum_i x_i$\n",
    "\n",
    "> We say that Beta is conjugate to the Bernoulli distribution: It produces a Beta posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Influence of $\\alpha$, $\\beta$ and the number of observations from the coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = scipy.stats.bernoulli.rvs(p=0.7, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_plot = np.linspace(0, 1, num=1000)\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "def update_plot(N, a, b):\n",
    "    ax.cla()\n",
    "    # Beta(a, b)\n",
    "    prior = scipy.stats.beta(a, b)\n",
    "    p = np.sum(coins[:N])\n",
    "    # Bernoulli\n",
    "    likelihood = (p_plot**p)*(1-p_plot)**(N-p)\n",
    "    likelihood = likelihood*1000/np.sum(likelihood)\n",
    "    # Beta(hat a, hat b)\n",
    "    posterior = scipy.stats.beta(a + np.sum(coins[:N]), b + N - np.sum(coins[:N]))\n",
    "    ax.plot(p_plot, prior.pdf(p_plot), label='prior')\n",
    "    ax.plot(p_plot, likelihood, label='likelihood')\n",
    "    ax.plot(p_plot, posterior.pdf(p_plot), label='posterior')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "widgets.interact(update_plot, N=SelSlider_nice(options=[1, 2, 5, 10, 20, 50, 100, 200, 500]),\n",
    "                 a=FloatSlider_nice(min=0.0, max=10, value=1),\n",
    "                 b=FloatSlider_nice(min=0.0, max=10, value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayesian approach online problems are just updates to the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "a = b = 1\n",
    "def update_plot(k):\n",
    "    ax.cla()\n",
    "    ax.plot(p_plot, scipy.stats.beta(a + np.sum(coins[:k]), \n",
    "                                     b + k - np.sum(coins[:k])).pdf(p_plot), label=str(i))\n",
    "    ax.set_title(k)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=1000, interval=200, \n",
    "                               repeat=True, blit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 Inference\n",
    "\n",
    "Note that we are missing the\n",
    "\n",
    "**Evidence/Marginal likelihood:** The normalizing constant $p(\\mathcal{D}|\\mathcal{M}_i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is information? Can we measure it?\n",
    "\n",
    "Information Theory is the mathematical study of the quantification and transmission of information proposed by **Claude Shannon** on this seminal work: *A Mathematical Theory of Communication*, 1948\n",
    "\n",
    "Shannon considered the output of a noisy source as a random variable $X$ taking $M$ possible values $\\mathcal{A} = \\{x_1, x_2, x_3, \\ldots, x_M\\}$\n",
    "\n",
    "Each value $x_i$ have an associated probability $P(X=x_i) = p_i$\n",
    "\n",
    "> What is the amount of information carried by $x_i$?\n",
    "\n",
    "Shannon defined the amount of information as\n",
    "\n",
    "$$\n",
    "I(x_i) = \\log_2 \\frac{1}{p_i},\n",
    "$$\n",
    "\n",
    "which is measured in **bits**\n",
    "\n",
    "> One bit is the amount of information needed to choose between two **equiprobable** states\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: A meteorological station that sends tomorrow's weather prediction\n",
    "\n",
    "The dictionary of messages: (1) Rainy, (2) Cloudy, (3) Partially cloudy, (4) Sunny\n",
    "\n",
    "Their probabilities are: $p_1=1/2$, $p_2=1/4$, $p_3=1/8$, $p_4=1/8$\n",
    "\n",
    "The minimum number of yes/no questions (equiprobable) needed to guess tomorrow's weather:\n",
    "\n",
    "- Is it going to rain? \n",
    "- No: Is it going to be cloudy?\n",
    "- No: Is it going to be sunny?\n",
    "\n",
    "Amount of information:\n",
    "- Rainy: $\\log_2 \\frac{1}{p_1} = \\log_2 2 = 1$ bits\n",
    "- Cloudy: $2$ bits \n",
    "- Partially cloudy and Sunny: $3$ bits\n",
    "\n",
    "> The larger the probability the smallest information it carries\n",
    "\n",
    "> Amount of information is also called surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shannon's entropy\n",
    "\n",
    "After defining the amount of information for a state Shannon's defined the average information of the source $X$ as\n",
    "\n",
    "$$\n",
    "H(X) = \\mathbb{E}_{x\\sim X}\\left [\\log_2 \\frac{1}{P(x)} \\right] = - \\sum_{i=1}^M p_i \\log_2 p_i  ~ \\text{[bits]}\n",
    "$$\n",
    "\n",
    "and called it the **entropy** of the source\n",
    "\n",
    "> Entropy is the \"average information of the source\"\n",
    "\n",
    "#### Properties:\n",
    "- Entropy is nonnegative: $H(X)>0$\n",
    "- Entropy is equal to zero when $p_j = 1 \\wedge p_i = 0, i \\neq j$\n",
    "- Entropy is maximum when $X$ is uniformly distributed $p_i = \\frac{1}{M}$, $H(X) = \\log_2(M)$\n",
    "\n",
    "> The more random the source is the larger its entropy\n",
    "\n",
    "Differential entropy for continuous variables as \n",
    "\n",
    "$$\n",
    "H(p) = - \\int p(x) \\log p(x) \\,dx ~ \\text{[nats]}\n",
    "$$\n",
    "\n",
    "where $p(x)$ is the probability density function (pdf) of $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Entropy: Kullback Leibler divergence\n",
    "\n",
    "Consider a continuous random variable $X$ and two distributions $q(x)$ and $p(x)$ defined on its probability space\n",
    "\n",
    "The relative entropy between these distributions is \n",
    "$$\n",
    "\\begin{align}\n",
    "D_{\\text{KL}} \\left [ p(x) || q(x) \\right] &= \\mathbb{E}_{x \\sim p(x)} \\left [ \\log \\frac{p(x)}{q(x)} \\right ] \\nonumber \\\\\n",
    "&= \\mathbb{E}_{x \\sim p(x)} \\left [ \\log p(x) \\right ]  - \\mathbb{E}_{x \\sim p(x)} \\left [ \\log q(x) \\right ],  \\nonumber \\\\\n",
    "&= \\int p(x) \\log p(x) \\,dx  - \\int p(x) \\log q(x) \\,dx  \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "which is also known as the Kullback-Leibler divergence\n",
    "\n",
    "- The left hand side term is the negative entropy of p(x)\n",
    "- The right hand side term is called the **cross-entropy of q(x) relative to p(x)** \n",
    "    - Cross entropy is the average information of distribution q(x)\n",
    "\n",
    "#### Intepretations of KL\n",
    "- Coding: Expected number of \"extra bits\" needed to code p(x) using a code optimal for q(x)\n",
    "- Bayesian modeling: Amount of information lost when q(x) is used as a model for p(x)\n",
    "\n",
    "#### Properties\n",
    "\n",
    "- Non-negative\n",
    "- Equal to zero only if $p(x) \\equiv q(x)$\n",
    "- Additive for independent distributions\n",
    "- Related to Mutual Information: $\\text{MI}(X, Y) = D_{\\text{KL}} \\left [ p(x, y) || p(x)p(y) \\right]$\n",
    "\n",
    "\n",
    "**Important:** \n",
    "\n",
    "KL divergence is asymmetric\n",
    "$$\n",
    "D_{\\text{KL}} \\left [ p(x) || q(x) \\right] \\neq D_{\\text{KL}} \\left [ q(x) || p(x) \\right]\n",
    "$$\n",
    "- Not a proper distance (no triangle inequility either)\n",
    "- Forward and Reverse KL have different meanings (we will explore them soon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative models\n",
    "\n",
    "Assume that we have $N$ continuous observations \n",
    "$$\n",
    "(x_1, x_2, \\ldots, x_N)\n",
    "$$ \n",
    "\n",
    "These observations come from a certain distribution which we don't know \n",
    "\n",
    "$$\n",
    "x_i \\sim p^*(x)\n",
    "$$\n",
    "\n",
    "The goal of **generative modeling** is to learn a probabilistic model \n",
    "\n",
    "$$\n",
    "p_\\theta(x)\n",
    "$$ \n",
    "\n",
    "with parameters $\\theta$ that \"mimics\" $p^*(x)$, *i.e.*\n",
    "\n",
    "> match  $p_\\theta (x)$ to $p^*(x)$\n",
    "\n",
    "We can express this mathematically by \n",
    "1. Select a parametric form for $p_\\theta (x)$\n",
    "1. Write the difference between $p_\\theta (x)$  and $p^*(x)$\n",
    "1. Minimize this difference as a function of $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How do we compute the difference between probability distributions?\n",
    "\n",
    "\n",
    "## KL divergence\n",
    "\n",
    "One way to do this is through the Kullback-Leibler (KL) divergence\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "D_{\\text{KL}} \\left [ p^*(x) || p_\\theta(x) \\right] &= \\mathbb{E}_{x \\sim p^*(x)} \\left [ \\log \\frac{p^*(x)}{p_\\theta(x)} \\right ] \\nonumber \\\\\n",
    "&= \\mathbb{E}_{x \\sim p^*(x)} \\left [ \\log p^*(x) \\right ]  - \\mathbb{E}_{x \\sim p^*(x)} \\left [ \\log p_\\theta(x) \\right ],  \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mathbb{E}_{x\\sim p(x)} [q(x) ] = \\int p(x) q(x) \\,dx\n",
    "$$\n",
    "is the expected value of $q(x)$ given that $x$ is sampled from $p(x)$\n",
    "\n",
    "Note that the KL divergence is non-negative but **asymmetric** (not a proper distance)\n",
    "\n",
    "\n",
    "**Problem:** We don't know $p^*(x)$, so we cannot evaluate $\\mathbb{E}_{x \\sim p^*(x)} \\left [ \\log p^*(x) \\right ]$\n",
    "\n",
    "\n",
    "## Relation with Maximum Likelihood\n",
    "\n",
    "We want to minimize the KL divergence as a function of $\\theta$\n",
    "\n",
    "The term $\\mathbb{E}_{x \\sim p^*(x)} \\left [ \\log p^*(x) \\right ]$ does not depend on $\\theta$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\min_\\theta D_{\\text{KL}} \\left [ p^*(x) || p_\\theta(x) \\right] = \\max_\\theta\\mathbb{E}_{x \\sim p^*(x)} \\left [ \\log p_\\theta(x) \\right ]\n",
    "$$\n",
    "\n",
    "> Minimizing the KL divergence between the real distribution and the model $\\equiv$ maximizing the log likelihood of the model given the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional material\n",
    "\n",
    "- Daniel Commenges, [\"Information Theory and Statistics: an overview\"](https://arxiv.org/pdf/1511.00860.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
